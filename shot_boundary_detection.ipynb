{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Shot Boundary Detection",
   "id": "531256a13fd9472a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-14T10:34:36.839414Z",
     "start_time": "2024-07-14T10:34:36.573284Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "\n",
    "import cv2\n",
    "import re\n",
    "import numpy as np\n",
    "from scenedetect import VideoManager, SceneManager\n",
    "from scenedetect.detectors import ContentDetector, ThresholdDetector\n",
    "from tqdm import tqdm\n"
   ],
   "id": "fcf0c657d5c64c29",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Shot Boundary Detection System\n",
    "\n",
    "This code performs shot boundary detection in video files using a combination of techniques, including content and threshold detection, histogram comparison, and optical flow analysis. Detected shot boundaries and keyframes are extracted and saved for further processing. \n",
    "\n",
    "### Techniques Used:\n",
    "- **ContentDetector**: Detects abrupt changes in frame content.\n",
    "- **ThresholdDetector**: Detects significant changes in frame properties.\n",
    "- **Histogram Comparison**: Identifies gradual transitions based on histogram differences.\n",
    "- **Optical Flow Analysis**: Measures motion magnitude to detect shot boundaries.\n",
    "\n",
    "The results are stored in specified output directories, with detected scenes saved to files and keyframes extracted from the start of each scene.\n",
    "\n"
   ],
   "id": "637b3b4a1dac43d7"
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2024-07-14T10:34:38.574245Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Configuration\n",
    "input_dir = 'preprocessed_videos/'\n",
    "output_dir = 'shot_boundaries/'\n",
    "keyframe_dir = 'keyframes/'\n",
    "\n",
    "# Configuration Google Colab\n",
    "# input_dir = '/content/drive/MyDrive/preprocessed_videos'\n",
    "# output_dir = '/content/drive/MyDrive/shot_boundaries'\n",
    "# keyframe_dir = '/content/drive/MyDrive/keyframes'\n",
    "\n",
    "min_scene_length = 15  # Minimum length of a scene in frames\n",
    "threshold = 30.0  # Threshold for the ThresholdDetector\n",
    "min_scene_len = 2  # Minimum number of frames a scene should last\n",
    "hist_threshold = 0.4  # Threshold for histogram comparison\n",
    "\n",
    "# Ensure the output and keyframe directories exist\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "os.makedirs(keyframe_dir, exist_ok=True)\n",
    "\n",
    "def calculate_histogram_difference(frame1, frame2):\n",
    "    hist1 = cv2.calcHist([frame1], [0], None, [256], [0, 256])\n",
    "    hist2 = cv2.calcHist([frame2], [0], None, [256], [0, 256])\n",
    "    cv2.normalize(hist1, hist1)\n",
    "    cv2.normalize(hist2, hist2)\n",
    "    return cv2.compareHist(hist1, hist2, cv2.HISTCMP_CORREL)\n",
    "\n",
    "def detect_shot_boundaries(video_path, output_path, keyframe_path):\n",
    "    if os.path.exists(output_path):\n",
    "        print(f\"Output file {output_path} already exists. Skipping shot boundary detection.\")\n",
    "        return\n",
    "    \n",
    "    video_manager = VideoManager([video_path])\n",
    "    scene_manager = SceneManager()\n",
    "\n",
    "    # Add ContentDetector and ThresholdDetector\n",
    "    scene_manager.add_detector(ContentDetector(threshold=30.0, min_scene_len=min_scene_length))\n",
    "    scene_manager.add_detector(ThresholdDetector(threshold=threshold, min_scene_len=min_scene_len))\n",
    "\n",
    "    video_manager.set_downscale_factor()\n",
    "    video_manager.start()\n",
    "    scene_manager.detect_scenes(frame_source=video_manager)\n",
    "    scenes = scene_manager.get_scene_list()\n",
    "    print(f\"Detected {len(scenes)} scenes in video {video_path}\")\n",
    "\n",
    "    # Additional processing for gradual transitions\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    prev_frame = None\n",
    "    prev_gray = None\n",
    "    frame_num = 0\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        if prev_frame is not None:\n",
    "            hist_diff = calculate_histogram_difference(prev_frame, frame)\n",
    "            if hist_diff < hist_threshold:\n",
    "                # Gradual transition detected\n",
    "                scenes.append((frame_num, frame_num + min_scene_len))\n",
    "            # Motion analysis using optical flow\n",
    "            if prev_gray is not None:\n",
    "                flow = cv2.calcOpticalFlowFarneback(prev_gray, gray_frame, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
    "                mag, ang = cv2.cartToPolar(flow[..., 0], flow[..., 1])\n",
    "                motion_magnitude = np.mean(mag)\n",
    "                if motion_magnitude > threshold:\n",
    "                    scenes.append((frame_num, frame_num + min_scene_len))\n",
    "        prev_frame = frame\n",
    "        prev_gray = gray_frame\n",
    "        frame_num += 1\n",
    "    cap.release()\n",
    "\n",
    "    # Remove duplicate and sort scenes\n",
    "    scenes = sorted(list(set(scenes)))\n",
    "    print(f\"Total scenes after processing: {len(scenes)}\")\n",
    "\n",
    "    # Save shot boundaries to a file\n",
    "    with open(output_path, 'w') as f:\n",
    "        for start_time, end_time in scenes:\n",
    "            f.write(f\"{start_time}, {end_time}\\n\")\n",
    "            # f.write(f\"{start_time.get_seconds()}, {end_time.get_seconds()}\\n\")\n",
    "            # f.write(f\"{start_time.get_frames()}, {end_time.get_frames()}\\n\")\n",
    "        print(f\"Shot boundaries saved to {output_path}\")\n",
    "\n",
    "    # Extract keyframes for each detected scene\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    for start, end in scenes:\n",
    "        keyframe_filename = os.path.join(keyframe_path, f\"{os.path.basename(video_path)}_start_{start}.jpg\")\n",
    "        if not os.path.exists(keyframe_filename):\n",
    "            cap.set(cv2.CAP_PROP_POS_FRAMES, int(start))\n",
    "            ret, frame = cap.read()\n",
    "            if ret:\n",
    "                cv2.imwrite(keyframe_filename, frame)\n",
    "    cap.release()\n",
    "    print(f\"Keyframes saved to {keyframe_path}\")\n",
    "\n",
    "\n",
    "def process_videos(video_files, output_directory, keyframe_directory):\n",
    "    for video_file in tqdm(video_files, desc=\"Detecting Shot Boundaries\", unit=\"video\"):\n",
    "        output_file = os.path.join(output_directory, os.path.splitext(os.path.basename(video_file))[0] + '_shots.txt')\n",
    "        keyframe_path = os.path.join(keyframe_directory, os.path.splitext(os.path.basename(video_file))[0])\n",
    "        os.makedirs(keyframe_path, exist_ok=True)\n",
    "        try:\n",
    "            detect_shot_boundaries(video_file, output_file, keyframe_path)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {video_file}: {e}\")\n",
    "\n",
    "def get_video_files(input_directory):\n",
    "    video_files = []\n",
    "    for root, _, files in os.walk(input_directory):\n",
    "        for file in files:\n",
    "            if file.endswith(('.mp4', '.avi', '.mov', '.mkv')):\n",
    "                match = re.search(r'\\d+', file)\n",
    "                if match:\n",
    "                    number = int(match.group())\n",
    "                    if 100 <= number <= 149:\n",
    "                        video_files.append(os.path.join(root, file))\n",
    "    return video_files\n",
    "\n",
    "\n",
    "print(\"Starting shot boundary detection...\")\n",
    "video_files = get_video_files(input_dir)\n",
    "print(f\"Found {len(video_files)} video files to process.\")\n",
    "print(\"Video files:\", video_files)\n",
    "process_videos(video_files, output_dir, keyframe_dir)\n",
    "print(\"Shot boundary detection completed successfully.\") "
   ],
   "id": "4189bfc95c5910d6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting shot boundary detection...\n",
      "Found 50 video files to process.\n",
      "Video files: ['preprocessed_videos/00120/00120.mp4', 'preprocessed_videos/00118/00118.mp4', 'preprocessed_videos/00127/00127.mp4', 'preprocessed_videos/00111/00111.mp4', 'preprocessed_videos/00129/00129.mp4', 'preprocessed_videos/00116/00116.mp4', 'preprocessed_videos/00142/00142.mp4', 'preprocessed_videos/00145/00145.mp4', 'preprocessed_videos/00128/00128.mp4', 'preprocessed_videos/00117/00117.mp4', 'preprocessed_videos/00110/00110.mp4', 'preprocessed_videos/00119/00119.mp4', 'preprocessed_videos/00126/00126.mp4', 'preprocessed_videos/00121/00121.mp4', 'preprocessed_videos/00144/00144.mp4', 'preprocessed_videos/00143/00143.mp4', 'preprocessed_videos/00103/00103.mp4', 'preprocessed_videos/00104/00104.mp4', 'preprocessed_videos/00132/00132.mp4', 'preprocessed_videos/00135/00135.mp4', 'preprocessed_videos/00134/00134.mp4', 'preprocessed_videos/00133/00133.mp4', 'preprocessed_videos/00105/00105.mp4', 'preprocessed_videos/00102/00102.mp4', 'preprocessed_videos/00146/00146.mp4', 'preprocessed_videos/00141/00141.mp4', 'preprocessed_videos/00148/00148.mp4', 'preprocessed_videos/00124/00124.mp4', 'preprocessed_videos/00123/00123.mp4', 'preprocessed_videos/00115/00115.mp4', 'preprocessed_videos/00112/00112.mp4', 'preprocessed_videos/00149/00149.mp4', 'preprocessed_videos/00140/00140.mp4', 'preprocessed_videos/00147/00147.mp4', 'preprocessed_videos/00113/00113.mp4', 'preprocessed_videos/00114/00114.mp4', 'preprocessed_videos/00122/00122.mp4', 'preprocessed_videos/00125/00125.mp4', 'preprocessed_videos/00107/00107.mp4', 'preprocessed_videos/00138/00138.mp4', 'preprocessed_videos/00100/00100.mp4', 'preprocessed_videos/00136/00136.mp4', 'preprocessed_videos/00109/00109.mp4', 'preprocessed_videos/00131/00131.mp4', 'preprocessed_videos/00130/00130.mp4', 'preprocessed_videos/00137/00137.mp4', 'preprocessed_videos/00108/00108.mp4', 'preprocessed_videos/00101/00101.mp4', 'preprocessed_videos/00106/00106.mp4', 'preprocessed_videos/00139/00139.mp4']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detecting Shot Boundaries:   0%|          | 0/50 [00:00<?, ?video/s]VideoManager is deprecated and will be removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output file shot_boundaries/00120_shots.txt already exists. Skipping shot boundary detection.\n",
      "Detected 185 scenes in video preprocessed_videos/00118/00118.mp4\n",
      "Total scenes after processing: 321\n",
      "Shot boundaries saved to shot_boundaries/00118_shots.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detecting Shot Boundaries:   4%|▍         | 2/50 [39:55<15:58:18, 1197.88s/video]VideoManager is deprecated and will be removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keyframes saved to keyframes/00118\n",
      "Detected 162 scenes in video preprocessed_videos/00127/00127.mp4\n",
      "Total scenes after processing: 300\n",
      "Shot boundaries saved to shot_boundaries/00127_shots.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detecting Shot Boundaries:   6%|▌         | 3/50 [52:16<13:09:07, 1007.39s/video]VideoManager is deprecated and will be removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keyframes saved to keyframes/00127\n",
      "Output file shot_boundaries/00111_shots.txt already exists. Skipping shot boundary detection.\n",
      "Output file shot_boundaries/00129_shots.txt already exists. Skipping shot boundary detection.\n",
      "Output file shot_boundaries/00116_shots.txt already exists. Skipping shot boundary detection.\n",
      "Output file shot_boundaries/00142_shots.txt already exists. Skipping shot boundary detection.\n",
      "Detected 4 scenes in video preprocessed_videos/00145/00145.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detecting Shot Boundaries:  16%|█▌        | 8/50 [1:03:37<4:08:43, 355.33s/video]VideoManager is deprecated and will be removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total scenes after processing: 4\n",
      "Shot boundaries saved to shot_boundaries/00145_shots.txt\n",
      "Keyframes saved to keyframes/00145\n",
      "Detected 168 scenes in video preprocessed_videos/00128/00128.mp4\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Post Processing",
   "id": "29f33eb12ed87356"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "8a42ca12cc959f9a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# PySceneDetect (same results as above)",
   "id": "b53ac014a99b2de"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import os\n",
    "import re\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from scenedetect import VideoManager\n",
    "from scenedetect import SceneManager\n",
    "from scenedetect.detectors import ContentDetector, ThresholdDetector\n",
    "\n",
    "# Configuration\n",
    "input_dir = 'preprocessed_videos/'\n",
    "output_dir = 'shot_boundaries_test/'\n",
    "keyframe_dir = 'keyframes_test/'\n",
    "\n",
    "# Ensure the output and keyframe directories exist\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "os.makedirs(keyframe_dir, exist_ok=True)\n",
    "\n",
    "def detect_shot_boundaries(video_path, output_path, keyframe_path, content_threshold=30.0, min_scene_len=15, pixel_threshold=12):\n",
    "    video_manager = VideoManager([video_path])\n",
    "    scene_manager = SceneManager()\n",
    "    \n",
    "    # Add ContentDetector and ThresholdDetector with customizable parameters\n",
    "    scene_manager.add_detector(ContentDetector(threshold=content_threshold, min_scene_len=min_scene_len))\n",
    "    scene_manager.add_detector(ThresholdDetector(threshold=pixel_threshold, min_scene_len=min_scene_len))\n",
    "\n",
    "    video_manager.set_downscale_factor()\n",
    "    video_manager.start()\n",
    "    scene_manager.detect_scenes(frame_source=video_manager)\n",
    "    scenes = scene_manager.get_scene_list()\n",
    "\n",
    "    print(f\"Detected {len(scenes)} scenes in video {video_path}\")\n",
    "\n",
    "    # Save shot boundaries to a file\n",
    "    with open(output_path, 'w') as f:\n",
    "        for start_time, end_time in scenes:\n",
    "            f.write(f\"{start_time.get_frames()}, {end_time.get_frames()}\\n\")\n",
    "    print(f\"Shot boundaries saved to {output_path}\")\n",
    "\n",
    "    # Extract keyframes for each detected scene\n",
    "    if not os.path.exists(keyframe_path):\n",
    "        os.makedirs(keyframe_path)\n",
    "    \n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    for i, (start, end) in enumerate(scenes):\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, start.get_frames())\n",
    "        ret, frame = cap.read()\n",
    "        if ret:\n",
    "            keyframe_filename = os.path.join(keyframe_path, f\"{os.path.splitext(os.path.basename(video_path))[0]}_Scene-{i + 1}.jpg\")\n",
    "            cv2.imwrite(keyframe_filename, frame)\n",
    "    cap.release()\n",
    "    print(f\"Keyframes saved to {keyframe_path}\")\n",
    "\n",
    "def process_videos(video_files, output_directory, keyframe_directory, content_threshold=30.0, min_scene_len=15, pixel_threshold=12):\n",
    "    for video_file in tqdm(video_files, desc=\"Detecting Shot Boundaries\", unit=\"video\"):\n",
    "        output_file = os.path.join(output_directory, os.path.splitext(os.path.basename(video_file))[0] + '_shots.txt')\n",
    "        keyframe_path = os.path.join(keyframe_directory, os.path.splitext(os.path.basename(video_file))[0])\n",
    "        os.makedirs(keyframe_path, exist_ok=True)\n",
    "        try:\n",
    "            detect_shot_boundaries(video_file, output_file, keyframe_path, content_threshold, min_scene_len, pixel_threshold)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {video_file}: {e}\")\n",
    "\n",
    "def get_video_files(input_directory):\n",
    "    video_files = []\n",
    "    for root, _, files in os.walk(input_directory):\n",
    "        for file in files:\n",
    "            if file.endswith(('.mp4', '.avi', '.mov', '.mkv')):\n",
    "                match = re.search(r'\\d+', file)\n",
    "                if match:\n",
    "                    number = int(match.group())\n",
    "                    if 126 <= number <= 149:\n",
    "                        video_files.append(os.path.join(root, file))\n",
    "    return video_files\n",
    "\n",
    "print(\"Starting shot boundary detection...\")\n",
    "video_files = get_video_files(input_dir)\n",
    "print(f\"Found {len(video_files)} video files to process.\")\n",
    "print(\"Video files:\", video_files)\n",
    "process_videos(video_files, output_dir, keyframe_dir, content_threshold=30.0, min_scene_len=15, pixel_threshold=12)\n",
    "print(\"Shot boundary detection completed successfully.\")\n"
   ],
   "id": "9c711554ba5c0be7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Frame Differencing (poor results but could maybe be used in combination with other techniques)\n",
    "\n",
    "### Description and Parameters for Shot Boundary Detection using Frame Differencing\n",
    "\n",
    "This script performs shot boundary detection on a set of videos using the frame differencing technique. Frame differencing involves calculating the difference between consecutive frames to detect abrupt changes and gradual transitions, indicating scene changes. Keyframes for each detected scene are extracted and saved.\n",
    "\n",
    "#### Parameters:\n",
    "\n",
    "- **frame_diff_threshold**: Threshold for detecting abrupt changes between consecutive frames. A lower value makes the detection more sensitive.\n",
    "- **accumulated_diff_threshold**: Threshold for detecting gradual transitions by accumulating frame differences over several frames.\n",
    "- **min_scene_len**: Minimum length of a scene in frames to filter out very short scenes.\n",
    "\n",
    "#### Workflow:\n",
    "\n",
    "1. **Frame Differencing**:\n",
    "   - The `calculate_frame_difference` function computes the difference between two frames and converts it to grayscale.\n",
    "   - The `detect_shot_boundaries` function processes each frame to detect scene changes using both abrupt and gradual transitions.\n",
    "   \n",
    "2. **Scene Detection**:\n",
    "   - Abrupt scene changes are detected when the difference between consecutive frames exceeds `frame_diff_threshold`.\n",
    "   - Gradual transitions are detected when the accumulated difference over several frames exceeds `accumulated_diff_threshold`.\n",
    "   - Detected scenes are saved to a file.\n",
    "\n",
    "3. **Keyframe Extraction**:\n",
    "   - A keyframe is extracted for each detected scene and saved as an image.\n"
   ],
   "id": "8f926d49b5150c72"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import os\n",
    "import re\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Configuration\n",
    "input_dir = 'preprocessed_videos/'\n",
    "output_dir = 'shot_boundaries_test/'\n",
    "keyframe_dir = 'keyframes_test/'\n",
    "\n",
    "# Ensure the output and keyframe directories exist\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "os.makedirs(keyframe_dir, exist_ok=True)\n",
    "\n",
    "# Parameters for frame differencing\n",
    "frame_diff_threshold = 50.0  # Threshold for frame difference\n",
    "accumulated_diff_threshold = 500.0  # Threshold for accumulated frame difference\n",
    "min_scene_len = 15  # Minimum length of a scene in frames\n",
    "\n",
    "def calculate_frame_difference(frame1, frame2):\n",
    "    diff = cv2.absdiff(frame1, frame2)\n",
    "    gray_diff = cv2.cvtColor(diff, cv2.COLOR_BGR2GRAY)\n",
    "    return np.sum(gray_diff)\n",
    "\n",
    "def detect_shot_boundaries(video_path, output_path, keyframe_path, frame_diff_threshold=50.0, accumulated_diff_threshold=500.0, min_scene_len=15):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        print(f\"Error opening video file {video_path}\")\n",
    "        return\n",
    "\n",
    "    frame_num = 0\n",
    "    prev_frame = None\n",
    "    scenes = []\n",
    "    current_scene_start = 0\n",
    "    accumulated_diff = 0\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        if prev_frame is not None:\n",
    "            frame_diff = calculate_frame_difference(prev_frame, frame)\n",
    "            accumulated_diff += frame_diff\n",
    "\n",
    "            if frame_diff > frame_diff_threshold and (frame_num - current_scene_start) > min_scene_len:\n",
    "                scenes.append((current_scene_start, frame_num))\n",
    "                current_scene_start = frame_num\n",
    "                accumulated_diff = 0\n",
    "            elif accumulated_diff > accumulated_diff_threshold and (frame_num - current_scene_start) > min_scene_len:\n",
    "                scenes.append((current_scene_start, frame_num))\n",
    "                current_scene_start = frame_num\n",
    "                accumulated_diff = 0\n",
    "\n",
    "        prev_frame = frame\n",
    "        frame_num += 1\n",
    "\n",
    "    # Add the last scene\n",
    "    if current_scene_start < frame_num:\n",
    "        scenes.append((current_scene_start, frame_num))\n",
    "\n",
    "    cap.release()\n",
    "\n",
    "    print(f\"Detected {len(scenes)} scenes in video {video_path}\")\n",
    "\n",
    "    # Save shot boundaries to a file\n",
    "    with open(output_path, 'w') as f:\n",
    "        for start_frame, end_frame in scenes:\n",
    "            f.write(f\"{start_frame}, {end_frame}\\n\")\n",
    "    print(f\"Shot boundaries saved to {output_path}\")\n",
    "\n",
    "    # Extract keyframes for each detected scene\n",
    "    if not os.path.exists(keyframe_path):\n",
    "        os.makedirs(keyframe_path)\n",
    "    \n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    for i, (start, end) in enumerate(scenes):\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, start)\n",
    "        ret, frame = cap.read()\n",
    "        if ret:\n",
    "            keyframe_filename = os.path.join(keyframe_path, f\"{os.path.splitext(os.path.basename(video_path))[0]}_Scene-{i + 1}.jpg\")\n",
    "            cv2.imwrite(keyframe_filename, frame)\n",
    "    cap.release()\n",
    "    print(f\"Keyframes saved to {keyframe_path}\")\n",
    "\n",
    "def process_videos(video_files, output_directory, keyframe_directory, frame_diff_threshold=50.0, accumulated_diff_threshold=500.0, min_scene_len=15):\n",
    "    for video_file in tqdm(video_files, desc=\"Detecting Shot Boundaries\", unit=\"video\"):\n",
    "        output_file = os.path.join(output_directory, os.path.splitext(os.path.basename(video_file))[0] + '_shots.txt')\n",
    "        keyframe_path = os.path.join(keyframe_directory, os.path.splitext(os.path.basename(video_file))[0])\n",
    "        os.makedirs(keyframe_path, exist_ok=True)\n",
    "        try:\n",
    "            detect_shot_boundaries(video_file, output_file, keyframe_path, frame_diff_threshold, accumulated_diff_threshold, min_scene_len)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {video_file}: {e}\")\n",
    "\n",
    "def get_video_files(input_directory):\n",
    "    video_files = []\n",
    "    for root, _, files in os.walk(input_directory):\n",
    "        for file in files:\n",
    "            if file.endswith(('.mp4', '.avi', '.mov', '.mkv')):\n",
    "                match = re.search(r'\\d+', file)\n",
    "                if match:\n",
    "                    number = int(match.group())\n",
    "                    if 126 <= number <= 149:\n",
    "                        video_files.append(os.path.join(root, file))\n",
    "    return video_files\n",
    "\n",
    "print(\"Starting shot boundary detection...\")\n",
    "video_files = get_video_files(input_dir)\n",
    "print(f\"Found {len(video_files)} video files to process.\")\n",
    "print(\"Video files:\", video_files)\n",
    "process_videos(video_files, output_dir, keyframe_dir, frame_diff_threshold=50.0, accumulated_diff_threshold=500.0, min_scene_len=15)\n",
    "print(\"Shot boundary detection completed successfully.\")\n"
   ],
   "id": "608a62a8468cb857",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# TransNetV2\n",
    "\n",
    "Not working"
   ],
   "id": "796d9e76c455179"
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import re\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from transnetv2 import TransNetV2\n",
    "\n",
    "# Configuration\n",
    "input_dir = 'preprocessed_videos/'\n",
    "output_dir = 'shot_boundaries_test/'\n",
    "keyframe_dir = 'keyframes_test/'\n",
    "\n",
    "# Ensure the output and keyframe directories exist\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "os.makedirs(keyframe_dir, exist_ok=True)\n",
    "\n",
    "def detect_shot_boundaries(video_path, output_path, keyframe_path):\n",
    "    model = TransNetV2()\n",
    "    \n",
    "    # Get video frames and predictions\n",
    "    video_frames, single_frame_predictions, all_frame_predictions = model.predict_video(video_path)\n",
    "    \n",
    "    # Get scenes from predictions\n",
    "    scenes = model.predictions_to_scenes(single_frame_predictions)\n",
    "    \n",
    "    print(f\"Detected {len(scenes)} scenes in video {video_path}\")\n",
    "\n",
    "    # Save shot boundaries to a file\n",
    "    with open(output_path, 'w') as f:\n",
    "        for start_time, end_time in scenes:\n",
    "            f.write(f\"{start_time}, {end_time}\\n\")\n",
    "    print(f\"Shot boundaries saved to {output_path}\")\n",
    "\n",
    "    # Extract keyframes for each detected scene\n",
    "    if not os.path.exists(keyframe_path):\n",
    "        os.makedirs(keyframe_path)\n",
    "    \n",
    "    for i, (start, end) in enumerate(scenes):\n",
    "        keyframe_filename = os.path.join(keyframe_path, f\"{os.path.splitext(os.path.basename(video_path))[0]}_Scene-{i + 1}.jpg\")\n",
    "        cv2.imwrite(keyframe_filename, video_frames[start])\n",
    "    print(f\"Keyframes saved to {keyframe_path}\")\n",
    "\n",
    "def process_videos(video_files, output_directory, keyframe_directory):\n",
    "    for video_file in tqdm(video_files, desc=\"Detecting Shot Boundaries\", unit=\"video\"):\n",
    "        output_file = os.path.join(output_directory, os.path.splitext(os.path.basename(video_file))[0] + '_shots.txt')\n",
    "        keyframe_path = os.path.join(keyframe_directory, os.path.splitext(os.path.basename(video_file))[0])\n",
    "        os.makedirs(keyframe_path, exist_ok=True)\n",
    "        try:\n",
    "            detect_shot_boundaries(video_file, output_file, keyframe_path)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {video_file}: {e}\")\n",
    "\n",
    "def get_video_files(input_directory):\n",
    "    video_files = []\n",
    "    for root, _, files in os.walk(input_directory):\n",
    "        for file in files:\n",
    "            if file.endswith(('.mp4', '.avi', '.mov', '.mkv')):\n",
    "                match = re.search(r'\\d+', file)\n",
    "                if match:\n",
    "                    number = int(match.group())\n",
    "                    if 126 <= number <= 149:\n",
    "                        video_files.append(os.path.join(root, file))\n",
    "    return video_files\n",
    "\n",
    "print(\"Starting shot boundary detection...\")\n",
    "video_files = get_video_files(input_dir)\n",
    "print(f\"Found {len(video_files)} video files to process.\")\n",
    "print(\"Video files:\", video_files)\n",
    "process_videos(video_files, output_dir, keyframe_dir)\n",
    "print(\"Shot boundary detection completed successfully.\")\n"
   ],
   "id": "f0f6c23c21f8e06f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from transnetv2 import TransNetV2\n",
    "\n",
    "model = TransNetV2()\n",
    "model_dir=\"TransNetV2/inference/transnetv2-weights/\"\n",
    "state_dict = torch.load(\"transnetv2-pytorch-weights.pth\")\n",
    "model.load_state_dict(state_dict)\n",
    "model.eval().cuda()\n",
    "\n",
    "with torch.no_grad():\n",
    "    # shape: batch dim x video frames x frame height x frame width x RGB (not BGR) channels\n",
    "    input_video = torch.zeros(1, 100, 27, 48, 3, dtype=torch.uint8)\n",
    "    single_frame_pred, all_frame_pred = model(input_video.cuda())\n",
    "    \n",
    "    single_frame_pred = torch.sigmoid(single_frame_pred).cpu().numpy()\n",
    "    all_frame_pred = torch.sigmoid(all_frame_pred[\"many_hot\"]).cpu().numpy()"
   ],
   "id": "d60c904ffddc7b53",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
